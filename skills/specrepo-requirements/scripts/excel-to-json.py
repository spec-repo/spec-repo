#!/usr/bin/env python3
"""
ìš”êµ¬ì‚¬í•­ì •ì˜ì„œ xlsx â†’ 01-requirements/requirements.json ë³€í™˜ ìŠ¤í¬ë¦½íŠ¸.

Usage:
    uv run --with openpyxl python3 excel-to-json.py <excel-file>
    uv run --with openpyxl python3 excel-to-json.py <excel-file> --merge upsert
    uv run --with openpyxl python3 excel-to-json.py <excel-file> --merge replace
    uv run --with openpyxl python3 excel-to-json.py <excel-file> --merge append
    uv run --with openpyxl python3 excel-to-json.py <excel-file> --out path/to/output.json

merge ì „ëµ:
    upsert  (ê¸°ë³¸) ID ê¸°ì¤€ ë®ì–´ì“°ê¸°, ê¸°ì¡´ì—ë§Œ ìˆëŠ” IDëŠ” ìœ ì§€
    replace         ì‹œíŠ¸ ì „ì²´ êµì²´
    append          ì‹ ê·œ IDë§Œ ì¶”ê°€, ê¸°ì¡´ IDëŠ” ìœ ì§€
"""

import sys
import json
import re
from datetime import datetime, timezone
from pathlib import Path

try:
    import openpyxl
except ImportError:
    print("ERROR: openpyxl not installed.", file=sys.stderr)
    print("Run: uv run --with openpyxl python3 excel-to-json.py <file>", file=sys.stderr)
    sys.exit(1)


# â”€â”€ ì»¬ëŸ¼ ë§¤í•‘: Excel í—¤ë” â†’ JSON í•„ë“œëª… â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# (í—¤ë”ëŠ” parse-excel.py ë°©ì‹ì˜ "r1 > r2" í˜•ì‹ì„ ë”°ë¦„)

# ê¸°ëŠ¥ ìš”êµ¬ì‚¬í•­ (ê¸°ëŠ¥_ìš”êµ¬ì‚¬í•­ ì‹œíŠ¸)
FUNC_PARENT_FIELDS = {
    "ìš”êµ¬ì‚¬í•­ ID":               "id",
    "ì œì•ˆìš”ì²­ì„œ > ìš”êµ¬ì‚¬í•­ ëª…":   "rfp_name",
    "ì œì•ˆìš”ì²­ì„œ > ìš”êµ¬ì‚¬í•­ ì„¤ëª…": "rfp_desc",
}
FUNC_SUB_FIELDS = {
    "ì„¸ë¶€ìš”êµ¬ì‚¬í•­ID":                          "sub_id",
    "ì—…ë¬´ê¸°ëŠ¥ > ëŒ€ë¶„ë¥˜":                       "category_major",
    "ì—…ë¬´ê¸°ëŠ¥ > ì¤‘ë¶„ë¥˜":                       "category_minor",
    "ê³ ê°ìš”êµ¬ì‚¬í•­":                            "customer_requirement",
    "ìƒì„¸ìš”êµ¬ì‚¬í•­":                            "detail_requirement",
    "ì„¤ê³„ ë° êµ¬í˜„ë°©ì•ˆ > ì „ì œì¡°ê±´ ë° êµ¬í˜„ë°©ì•ˆ":  "implementation",
    "ì„¤ê³„ ë° êµ¬í˜„ë°©ì•ˆ > ì œì•½ì‚¬í•­":              "constraints",
    "ì‚°ì¶œë¬¼":                                 "deliverable",
    "ê¸°ëŠ¥êµ¬ë¶„":                               "func_type",
    "ìš°ì„ ìˆœìœ„":                               "priority",
    "ì¶œì²˜":                                   "source",
    "ìš”êµ¬ì":                                 "requester",
    "ìš”ì²­ì¼":                                 "request_date",
    "ì™„ë£Œì¼":                                 "completion_date",
    "ì—…ë¬´ë‹´ë‹¹ì":                              "owner",
    "ë™ë£Œê²€í† ":                               "peer_review",
    "ë‹´ë‹¹ìì—°ë½ì²˜":                            "contact",
    "ì ìš©êµ¬ë¶„":                               "apply_type",
    "ìš”êµ¬ê´€ë¦¬ìƒíƒœ":                            "status",
    "ë³€ê²½ê·¼ê±°":                               "change_reason",
}

# ë¹„ê¸°ëŠ¥ ìš”êµ¬ì‚¬í•­ (ë¹„ê¸°ëŠ¥_ìš”êµ¬ì‚¬í•­ ì‹œíŠ¸)
NONFUNC_PARENT_FIELDS = {
    "ìš”êµ¬ì‚¬í•­ ID":               "id",
    "ì œì•ˆìš”ì²­ì„œ > ìš”êµ¬ì‚¬í•­ ëª…":   "rfp_name",
    "ì œì•ˆìš”ì²­ì„œ > ìš”êµ¬ì‚¬í•­ ì„¤ëª…": "rfp_desc",
}
NONFUNC_SUB_FIELDS = {
    "ìš”êµ¬ì‚¬í•­ID(ì„¸ë¶€)":                         "sub_id",
    "ì—…ë¬´ê¸°ëŠ¥ > ëŒ€ë¶„ë¥˜":                        "category_major",
    "ì—…ë¬´ê¸°ëŠ¥ > ì¤‘ë¶„ë¥˜":                        "category_minor",
    "ê³ ê°ìš”êµ¬ì‚¬í•­":                             "customer_requirement",
    "ìƒì„¸ìš”êµ¬ì‚¬í•­":                             "detail_requirement",
    "ìƒì„¸êµ¬í˜„ë°©ì•ˆ":                             "implementation",
    "ì‚°ì¶œë¬¼ëª…":                                "deliverable",
    "ê´€ë ¨ê·¼ê±°":                                "related_basis",
    "ê¸°ëŠ¥êµ¬ë¶„":                                "func_type",
    "ìš°ì„ ìˆœìœ„":                                "priority",
    "ì¶œì²˜":                                    "source",
    "ìš”êµ¬ì":                                  "requester",
    "ìš”ì²­ì¼":                                  "request_date",
    "ì™„ë£Œì¼":                                  "completion_date",
    "ì—…ë¬´ë‹´ë‹¹ì":                               "owner",
    "ë™ë£Œê²€í† ":                                "peer_review",
    "ë‹´ë‹¹ìì—°ë½ì²˜":                             "contact",
    "ì ìš©êµ¬ë¶„":                                "apply_type",
    "ìš”êµ¬ê´€ë¦¬ìƒíƒœ":                             "status",
    "ë³€ê²½ê·¼ê±°":                                "change_reason",
    "ì„¤ê³„ ë° êµ¬í˜„ ì œì•½ì‚¬í•­ > ì „ì œì¡°ê±´":          "design_precondition",
    "ì„¤ê³„ ë° êµ¬í˜„ ì œì•½ì‚¬í•­ > ì œì•½ì‚¬í•­":          "design_constraints",
}


# â”€â”€ ì €ìˆ˜ì¤€ ì…€ ìœ í‹¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def resolve_merged_cells(ws):
    """ë³‘í•©ëœ ì…€ì˜ ê°’ì„ ëª¨ë“  ë³‘í•© ë²”ìœ„ì— ì±„ìš´ë‹¤."""
    merge_values = {}
    for merge_range in ws.merged_cells.ranges:
        top_left = ws.cell(row=merge_range.min_row, column=merge_range.min_col)
        value = top_left.value
        for row in range(merge_range.min_row, merge_range.max_row + 1):
            for col in range(merge_range.min_col, merge_range.max_col + 1):
                merge_values[(row, col)] = value
    return merge_values


def get_cell_value(ws, row, col, merge_map):
    coord = (row, col)
    if coord in merge_map:
        return merge_map[coord]
    return ws.cell(row=row, column=col).value


def detect_header_rows(ws, merge_map, max_col):
    """1~2í–‰ í—¤ë” íŒŒì‹±. (ì»¬ëŸ¼ëª… ëª©ë¡, ë°ì´í„° ì‹œì‘ í–‰) ë°˜í™˜."""
    row1 = [get_cell_value(ws, 1, c, merge_map) for c in range(1, max_col + 1)]
    row2 = [get_cell_value(ws, 2, c, merge_map) for c in range(1, max_col + 1)]

    has_subheader = any(
        row2[i] and row2[i] != row1[i] for i in range(len(row1))
    )

    if has_subheader:
        headers = []
        for i in range(max_col):
            r1 = str(row1[i]).strip() if row1[i] else ""
            r2 = str(row2[i]).strip() if row2[i] else ""
            if r2 and r2 != r1:
                headers.append(f"{r1} > {r2}" if r1 else r2)
            else:
                headers.append(r1)
        return headers, 3
    else:
        headers = [str(v).strip() if v else f"col_{i+1}" for i, v in enumerate(row1)]
        return headers, 2


# â”€â”€ íŒŒì‹± ë¡œì§ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def parse_version_from_filename(filepath):
    """íŒŒì¼ëª…ì—ì„œ ë²„ì „ ì¶”ì¶œ (_0.7.8, _v0.7.8, _0.7.8v íŒ¨í„´). ì—†ìœ¼ë©´ None."""
    name = Path(filepath).stem
    m = re.search(r'_v?(\d+\.\d+\.\d+)v?', name)
    return m.group(1) if m else None


def find_project_root(start_dir):
    """AGENTS.md ë˜ëŠ” .git ì´ ìˆëŠ” ë””ë ‰í† ë¦¬ë¥¼ í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¡œ ë°˜í™˜."""
    current = Path(start_dir).resolve()
    for _ in range(10):
        if (current / "AGENTS.md").exists() or (current / ".git").is_dir():
            return current
        parent = current.parent
        if parent == current:
            break
        current = parent
    return Path(start_dir).resolve()


def parse_requirements_sheet(ws, parent_fields, sub_fields):
    """
    ìš”êµ¬ì‚¬í•­ ì‹œíŠ¸ë¥¼ íŒŒì‹±í•´ normalized êµ¬ì¡°ë¡œ ë°˜í™˜í•œë‹¤.

    Returns: [{"id": ..., "rfp_name": ..., "rfp_desc": ..., "sub_requirements": [...]}, ...]
    """
    max_row, max_col = ws.max_row, ws.max_column
    if max_row < 3 or max_col == 0:
        return []

    merge_map = resolve_merged_cells(ws)
    headers, data_start = detect_header_rows(ws, merge_map, max_col)

    parents = {}
    parent_order = []

    for r in range(data_start, max_row + 1):
        row_vals = [get_cell_value(ws, r, c, merge_map) for c in range(1, max_col + 1)]

        if all(v is None or str(v).strip() == "" for v in row_vals):
            continue

        row = {}
        for i, h in enumerate(headers):
            if i < len(row_vals):
                val = row_vals[i]
                row[h] = str(val).strip() if val is not None else ""

        parent_id = row.get("ìš”êµ¬ì‚¬í•­ ID", "").strip()
        if not parent_id:
            continue

        if parent_id not in parents:
            entry = {"id": parent_id, "sub_requirements": []}
            for excel_h, json_f in parent_fields.items():
                if json_f != "id":
                    entry[json_f] = row.get(excel_h, "")
            parents[parent_id] = entry
            parent_order.append(parent_id)

        sub = {}
        for excel_h, json_f in sub_fields.items():
            sub[json_f] = row.get(excel_h, "")
        parents[parent_id]["sub_requirements"].append(sub)

    return [parents[pid] for pid in parent_order]


def detect_sheet_type(sheet_name):
    """ì‹œíŠ¸ëª…ìœ¼ë¡œ functional/nonfunctional íŒë³„."""
    if "ë¹„ê¸°ëŠ¥" in sheet_name:
        return "nonfunctional"
    if "ê¸°ëŠ¥" in sheet_name:
        return "functional"
    return None


def merge_requirements(existing, incoming, strategy):
    """merge ì „ëµ ì ìš©."""
    if strategy == "replace":
        return incoming

    existing_map = {item["id"]: i for i, item in enumerate(existing)}

    if strategy == "append":
        result = list(existing)
        for item in incoming:
            if item["id"] not in existing_map:
                result.append(item)
        return result

    # upsert (ê¸°ë³¸)
    result = list(existing)
    for item in incoming:
        pid = item["id"]
        if pid in existing_map:
            result[existing_map[pid]] = item
        else:
            result.append(item)
    return result


# â”€â”€ ì§„ì…ì  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def main():
    args = sys.argv[1:]

    if not args or args[0] in ("-h", "--help"):
        print(__doc__)
        sys.exit(0)

    filepath = Path(args[0])
    if not filepath.exists():
        print(f"ERROR: íŒŒì¼ ì—†ìŒ: {filepath}", file=sys.stderr)
        sys.exit(1)

    merge_strategy = "upsert"
    out_path = None

    i = 1
    while i < len(args):
        if args[i] == "--merge" and i + 1 < len(args):
            merge_strategy = args[i + 1]
            i += 2
        elif args[i] == "--out" and i + 1 < len(args):
            out_path = Path(args[i + 1])
            i += 2
        else:
            i += 1

    if merge_strategy not in ("upsert", "replace", "append"):
        print("ERROR: --mergeëŠ” upsert|replace|append ì¤‘ í•˜ë‚˜ì—¬ì•¼ í•©ë‹ˆë‹¤.", file=sys.stderr)
        sys.exit(1)

    if out_path is None:
        project_root = find_project_root(filepath.parent)
        out_path = project_root / "01-requirements" / "requirements.json"

    out_path.parent.mkdir(parents=True, exist_ok=True)

    version = parse_version_from_filename(filepath)

    # ê¸°ì¡´ JSON ë¡œë“œ
    existing_data = {
        "_meta": {"version": None, "history": []},
        "_columns": {
            "functional": {
                "parent": list(FUNC_PARENT_FIELDS.values()),
                "sub": list(FUNC_SUB_FIELDS.values()),
            },
            "nonfunctional": {
                "parent": list(NONFUNC_PARENT_FIELDS.values()),
                "sub": list(NONFUNC_SUB_FIELDS.values()),
            },
        },
        "functional": [],
        "nonfunctional": [],
    }
    if out_path.exists():
        try:
            with open(out_path, encoding="utf-8") as f:
                loaded = json.load(f)
            existing_data["functional"]   = loaded.get("functional", [])
            existing_data["nonfunctional"] = loaded.get("nonfunctional", [])
            existing_data["_meta"]         = loaded.get("_meta", existing_data["_meta"])
        except Exception as e:
            print(f"WARNING: ê¸°ì¡´ JSON ë¡œë“œ ì‹¤íŒ¨, ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤: {e}", file=sys.stderr)

    # Excel íŒŒì‹±
    try:
        wb = openpyxl.load_workbook(filepath, data_only=True)
    except Exception as e:
        print(f"ERROR: Excel íŒŒì¼ ì—´ê¸° ì‹¤íŒ¨: {e}", file=sys.stderr)
        sys.exit(1)

    any_imported = False
    for sheet_name in wb.sheetnames:
        sheet_type = detect_sheet_type(sheet_name)
        if sheet_type is None:
            print(f"INFO: ì‹œíŠ¸ '{sheet_name}' ê±´ë„ˆëœ€ (ê¸°ëŠ¥/ë¹„ê¸°ëŠ¥ íŒë³„ ë¶ˆê°€)")
            continue

        ws = wb[sheet_name]
        if sheet_type == "functional":
            incoming = parse_requirements_sheet(ws, FUNC_PARENT_FIELDS, FUNC_SUB_FIELDS)
        else:
            incoming = parse_requirements_sheet(ws, NONFUNC_PARENT_FIELDS, NONFUNC_SUB_FIELDS)

        if not incoming:
            print(f"INFO: ì‹œíŠ¸ '{sheet_name}'ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            continue

        merged = merge_requirements(existing_data[sheet_type], incoming, merge_strategy)
        existing_data[sheet_type] = merged
        any_imported = True
        print(f"âœ… [{sheet_name}] {len(incoming)}ê°œ íŒŒì‹± â†’ {merge_strategy} ì ìš©")

    if not any_imported:
        print("ERROR: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.", file=sys.stderr)
        sys.exit(1)

    # ë©”íƒ€ ì—…ë°ì´íŠ¸
    if version:
        existing_data["_meta"]["version"] = version
    existing_data["_meta"].setdefault("history", []).append({
        "version": version,
        "imported_at": datetime.now(timezone.utc).strftime("%Y-%m-%dT%H:%M:%SZ"),
        "source": filepath.name,
        "merge": merge_strategy,
    })

    with open(out_path, "w", encoding="utf-8") as f:
        json.dump(existing_data, f, ensure_ascii=False, indent=2)

    total_func    = len(existing_data.get("functional", []))
    total_nonfunc = len(existing_data.get("nonfunctional", []))
    print(f"\nğŸ“„ ì €ì¥: {out_path}")
    print(f"   ê¸°ëŠ¥ ìš”êµ¬ì‚¬í•­:   {total_func}ê°œ")
    print(f"   ë¹„ê¸°ëŠ¥ ìš”êµ¬ì‚¬í•­: {total_nonfunc}ê°œ")


if __name__ == "__main__":
    main()
